import requests
from bs4 import BeautifulSoup
import time

# Ana sayfa URL'si
main_url = "https://kpfu.ru/main_page?p_sub=7860&p_id=9414&p_order=1"

# Ana sayfanÄ±n iÃ§eriÄŸini Ã§ek
try:
    response = requests.get(main_url, timeout=15)  # Timeout ekledik
    response.raise_for_status()  # HTTP hatalarÄ±nÄ± yakala
except requests.exceptions.RequestException as e:
    print(f"Hata: {e}")
    exit()

# HTML iÃ§eriÄŸini iÅŸle
soup = BeautifulSoup(response.text, "html.parser")

# TÃ¼m <a> etiketlerini bul (target="_blank" olanlarÄ± dahil)
links = soup.find_all("a", href=True)

# Sadece "http://kpfu.ru/" ile baÅŸlayan linkleri al
kpfu_links = []
for link in links:
    href = link["href"].strip()  # BaÅŸÄ±ndaki ve sonundaki boÅŸluklarÄ± kaldÄ±r
    if href.startswith("http://kpfu.ru/"):  # Burada doÄŸru koÅŸul saÄŸlanÄ±yor
        kpfu_links.append(href)

# Bulunan linkleri yazdÄ±r
print("\nğŸ”— KPFU Linkleri (target='_blank'):")
for link in kpfu_links:
    print(link)

# Mail adreslerini saklayacak liste
emails = []

# KPFU sayfalarÄ±ndaki mailto linklerini Ã§ek
for profile_url in kpfu_links:
    try:
        print(f"\nâ³ Ä°ÅŸleniyor: {profile_url}")
        profile_response = requests.get(profile_url, timeout=15)
        profile_response.raise_for_status()
        
        profile_soup = BeautifulSoup(profile_response.text, "html.parser")
        mailto_links = profile_soup.find_all("a", href=True)

        for mail_link in mailto_links:
            href = mail_link["href"].strip()  # Fazladan boÅŸluklarÄ± temizle
            if href.startswith("mailto:"):
                email = href.replace("mailto:", "").strip()
                if email not in emails:
                    emails.append(email)

    except requests.exceptions.RequestException as e:
        print(f"âš ï¸ {profile_url} adresine eriÅŸilemedi: {e}")
    
    # Ã‡ok hÄ±zlÄ± istek atmayÄ± Ã¶nlemek iÃ§in bekleme ekledik
    time.sleep(1)

# Bulunan e-postalarÄ± yazdÄ±r
print("\nğŸ“§ Bulunan E-postalar:")
for email in emails:
    print(email)
